defaults:
  - network: dqn_value_network
  - agent: dqn_agent
  - learner: dqn_learner

environment:
# 43_var_features  43_var_and_sb_features
  observation_function: '43_var_and_sb_features' 
  information_function: 'default'
  reward_function: 'retro_binary_fathomed'
  scip_params: 'gasse_2019'

learner:
  path_to_save: './'
  agent_reward: 'retro_binary_fathomed'

instances:
  co_class: 'set_covering'
  co_class_kwargs:
    'n_rows': 500
    'n_cols': 1000

experiment:
  seed: 0
  device: 'cuda:0'
  num_epochs: 5000000

