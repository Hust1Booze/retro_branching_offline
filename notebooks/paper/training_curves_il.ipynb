{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "from retro_branching.utils import get_most_recent_checkpoint_foldername, PlotAesthetics\n",
    "\n",
    "import glob\n",
    "import gzip\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import copy\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import math\n",
    "from ordered_set import OrderedSet\n",
    "import time\n",
    "from sqlitedict import SqliteDict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", 100, \"display.max_columns\", None)\n",
    "from tabulate import tabulate\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 100x100 RL\n",
    "# agent_to_path = {'RL': '/scratch/datasets/retro_branching/dqn_learner/dqn_gnn/dqn_gnn_1376/database/'}\n",
    "\n",
    "# 500x1000 RL\n",
    "# agent_to_path = {'RL': '/scratch/datasets/retro_branching/dqn_learner/dqn_gnn/dqn_gnn_1236/database/'}\n",
    "\n",
    "# 500x1000 ablating sub-trees\n",
    "agent_to_path = {'Full': '/scratch/datasets/retro_branching/dqn_learner/dqn_gnn/dqn_gnn_1405/database/',\n",
    "                 'Retrospective': '/scratch/datasets/retro_branching/dqn_learner/dqn_gnn/dqn_gnn_1236/database/',\n",
    "                 'Fathomed': '/scratch/datasets/retro_branching/dqn_learner/dqn_gnn/dqn_gnn_1464/database/'}\n",
    "# agent_to_path = {'No sub-trees': '/scratch/datasets/retro_branching/dqn_learner/dqn_gnn/dqn_gnn_1405/database/'}\n",
    "# agent_to_path = {'No sub-trees': '/scratch/datasets/retro_branching/dqn_learner/dqn_gnn/dqn_gnn_1412/database/'}\n",
    "\n",
    "# 500x1000 Etheve et al. baseline\n",
    "agent_to_path = {'Step-Orig': '/scratch/datasets/retro_branching/dqn_learner/dqn_gnn/dqn_gnn_1405/database/',\n",
    "                 'Step-Retro': '/scratch/datasets/retro_branching/dqn_learner/dqn_gnn/dqn_gnn_1236/database/',\n",
    "                 'Etheve': '/scratch/datasets/retro_branching/dqn_learner/dqn_gnn/dqn_gnn_1471/database/',\n",
    "                 'Etheve-Orig': '/scratch/datasets/retro_branching/dqn_learner/dqn_gnn/dqn_gnn_1471/database/'}\n",
    "#                  'Etheve-Retro': '/scratch/datasets/retro_branching/dqn_learner/dqn_gnn/dqn_gnn_1472/database/'}\n",
    "agent_to_path = {\n",
    "#                  'Step-Orig': '/scratch/datasets/retro_branching/dqn_learner/dqn_gnn/dqn_gnn_1479/database/',\n",
    "                 'Step-Retro': '/scratch/datasets/retro_branching/dqn_learner/dqn_gnn/dqn_gnn_1481/database/',\n",
    "                 'Etheve': '/scratch/datasets/retro_branching/dqn_learner/dqn_gnn/dqn_gnn_1484/database/',\n",
    "                 'MAB-Retro': '/scratch/datasets/retro_branching/dqn_learner/dqn_gnn/dqn_gnn_1485/database/',\n",
    "                }\n",
    "\n",
    "# # 100x100 ablating sub-trees\n",
    "# agent_to_path = {'No sub-trees': '/scratch/datasets/retro_branching/dqn_learner/dqn_gnn/dqn_gnn_1397/database/',\n",
    "#                  'Sub-trees': '/scratch/datasets/retro_branching/dqn_learner/dqn_gnn/dqn_gnn_1376/database/'}\n",
    "\n",
    "# agent_to_path = {'No sub-trees': '/scratch/datasets/retro_branching/dqn_learner/dqn_gnn/dqn_gnn_1412/database/',\n",
    "#                  'Sub-trees': '/scratch/datasets/retro_branching/dqn_learner/dqn_gnn/dqn_gnn_1411/database/'}\n",
    "\n",
    "\n",
    "# agent_to_path = {'DQN': '/scratch/datasets/retro_branching/dqn_learner/dqn_gnn/dqn_gnn_1437/database/',\n",
    "#                  'n-step DQN': '/scratch/datasets/retro_branching/dqn_learner/dqn_gnn/dqn_gnn_1438/database/',\n",
    "#                  'M-DQN': '/scratch/datasets/retro_branching/dqn_learner/dqn_gnn/dqn_gnn_1439/database/',\n",
    "#                  'n-step M-DQN': '/scratch/datasets/retro_branching/dqn_learner/dqn_gnn/dqn_gnn_1436/database/'}\n",
    "\n",
    "\n",
    "\n",
    "# # 250x500 ablating sub-trees\n",
    "# agent_to_path = {'Full': '/scratch/datasets/retro_branching/dqn_learner/dqn_gnn/dqn_gnn_1440/database/',\n",
    "#                  'Retrospective': '/scratch/datasets/retro_branching/dqn_learner/dqn_gnn/dqn_gnn_1436/database/',\n",
    "# #                  'Retrospective': '/scratch/datasets/retro_branching/dqn_learner/dqn_gnn/dqn_gnn_1437/database/',\n",
    "#                 }\n",
    "\n",
    "# # 1000x1000 \n",
    "# agent_to_path = {'DQN': '/scratch/datasets/retro_branching/dqn_learner/dqn_gnn/dqn_gnn_1448/database/',\n",
    "#                  'n-step M-DQN': '/scratch/datasets/retro_branching/dqn_learner/dqn_gnn/dqn_gnn_1450/database/',\n",
    "# #                  'Retrospective': '/scratch/datasets/retro_branching/dqn_learner/dqn_gnn/dqn_gnn_1437/database/',\n",
    "#                 }\n",
    "\n",
    "agent_to_path = {\n",
    "#                  'Step-Orig': '/scratch/datasets/retro_branching/dqn_learner/dqn_gnn/dqn_gnn_1479/database/',\n",
    "                 'il_10': '/data/ltf/code/retro_branching_offline/outputs/2024-09-24/19-04-41/il_10/gnn/gnn_0/database/',\n",
    "\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading logs for il_10 agent from /data/ltf/code/retro_branching_offline/outputs/2024-09-24/19-04-41/il_10/gnn/gnn_0/database/...\n",
      "Loaded il_10 agent episodes log in 0.004 s\n",
      "Loaded il_10 agent epochs log in 4.659 s\n",
      "\n",
      "All agent logs loaded.\n"
     ]
    }
   ],
   "source": [
    "# load agent logs\n",
    "episodes_logs_dict, epochs_logs_dict = {}, {}\n",
    "agent_name_to_display_name = {}\n",
    "for display_name, path in agent_to_path.items():\n",
    "    print(f'\\nLoading logs for {display_name} agent from {path}...')\n",
    "    start_t = time.time()\n",
    "    episodes_logs_dict[display_name], epochs_logs_dict[display_name] = {}, {}\n",
    "    while True:\n",
    "        try:\n",
    "            with SqliteDict(path+'episodes_log.sqlite') as log:\n",
    "                for key, val in log.items():\n",
    "                    # read into memory\n",
    "                    episodes_logs_dict[display_name][key] = val\n",
    "                log.close()\n",
    "            break\n",
    "        except:\n",
    "            # database locked since is being written to, wait and try again\n",
    "            time.sleep(1)\n",
    "    print(f'Loaded {display_name} agent episodes log in {time.time() - start_t:.3f} s')\n",
    "    start_t = time.time()\n",
    "    while True:\n",
    "        try:\n",
    "            with SqliteDict(path+'epochs_log.sqlite') as log:\n",
    "                for key, val in log.items():\n",
    "                    # read into memory\n",
    "                    epochs_logs_dict[display_name][key] = val\n",
    "                log.close()\n",
    "                break\n",
    "        except:\n",
    "            # database locked since is being written to, wait and try again\n",
    "            time.sleep(1)\n",
    "    print(f'Loaded {display_name} agent epochs log in {time.time() - start_t:.3f} s')\n",
    "print(f'\\nAll agent logs loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['agent_name', 'agent_device', 'lr', 'learner_name', 'train_logits', 'train_target', 'train_num_candidates', 'valid_logits', 'valid_target', 'valid_num_candidates', 'mean_train_loss', 'n_train_samples_processed', 'train_epoch_run_time', 'mean_valid_loss', 'n_valid_samples_processed', 'valid_epoch_run_time', 'epoch_counter'])\n",
      "num_epochs not found in agent il_10 log, estimating...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_loss</th>\n",
       "      <th>mean_valid_loss</th>\n",
       "      <th>num_epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.964586</td>\n",
       "      <td>3.420622</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.964586</td>\n",
       "      <td>3.420622</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.360586</td>\n",
       "      <td>3.302969</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_train_loss  mean_valid_loss  num_epochs\n",
       "0         3.964586         3.420622           1\n",
       "1         3.964586         3.420622           2\n",
       "2         3.360586         3.302969           3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_loss</th>\n",
       "      <th>mean_valid_loss</th>\n",
       "      <th>num_epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.964586</td>\n",
       "      <td>3.420622</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.964586</td>\n",
       "      <td>3.420622</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.360586</td>\n",
       "      <td>3.302969</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_train_loss  mean_valid_loss  num_epochs\n",
       "0         3.964586         3.420622           1\n",
       "1         3.964586         3.420622           2\n",
       "2         3.360586         3.302969           3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_df = defaultdict(list)\n",
    "for agent, log in epochs_logs_dict.items():\n",
    "    print(log.keys())\n",
    "    \n",
    "    # yvals\n",
    "    _df['mean_train_loss'].extend(log['mean_train_loss'])\n",
    "    _df['mean_valid_loss'].extend(log['mean_valid_loss'])\n",
    "    #_df['epoch_counter'].extend(log['epoch_counter'])\n",
    "#     _df['reward'].extend(log['reward'])\n",
    "    #_df['R'].extend(log['R'])\n",
    "    if 'num_epochs' not in log:\n",
    "        print(f'num_epochs not found in agent {agent} log, estimating...')\n",
    "\n",
    "        _df['num_epochs'].extend([(ep+1) for ep in range(log['epoch_counter'] + 1)])    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "df = pd.DataFrame(_df)\n",
    "# print(df[:10])\n",
    "# print(df)\n",
    "display(df[:10])\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.plot(df['num_epochs'], df['mean_train_loss'], label = 'Train')\n",
    "plt.plot(df['num_epochs'], df['mean_valid_loss'], label = 'Valid')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "xaxis = 'num_epochs' # 'num_episodes' 'num_epochs' 'num_actor_steps'\n",
    "\n",
    "# rolling_window = None\n",
    "# rolling_window = int(5)\n",
    "# rolling_window = int(10)\n",
    "# rolling_window = int(50)\n",
    "# rolling_window = int(100)\n",
    "# rolling_window = int(150)\n",
    "# rolling_window = int(300)\n",
    "# rolling_window = int(500) # paper training curve\n",
    "rolling_window = int(1e3)\n",
    "# rolling_window = int(5e3)\n",
    "# rolling_window = int(10e3)\n",
    "\n",
    "xlog = False # False True\n",
    "ylog = True # False True\n",
    "\n",
    "xaxis_label_style = 'sci' # paper training curve\n",
    "yaxis_label_style = 'plain'\n",
    "\n",
    "xlim = None\n",
    "# xlim = [0, 2e5] # paper training curve\n",
    "# xlim = [0, 1e5]\n",
    "# xlim = [0, 1.5e5]\n",
    "xlim = [0, 2.3e5]\n",
    "ylim = None\n",
    "\n",
    "# legend = False # 'auto' False\n",
    "legend = 'auto'\n",
    "\n",
    "# scaling_factor = 0.6 # paper training curve\n",
    "# scaling_factor = 2.5\n",
    "scaling_factor = 0.4\n",
    "width_scaling_factor = 1\n",
    "height_scaling_factor = 1\n",
    "\n",
    "aesthetics = PlotAesthetics()\n",
    "# aesthetics.set_icml_paper_plot_aesthetics() # paper training curve\n",
    "aesthetics.set_icml_paper_plot_aesthetics(font_scale=0.4, linewidth=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original df:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_loss</th>\n",
       "      <th>mean_valid_loss</th>\n",
       "      <th>num_epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.964586</td>\n",
       "      <td>3.420622</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.964586</td>\n",
       "      <td>3.420622</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.360586</td>\n",
       "      <td>3.302969</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_train_loss  mean_valid_loss  num_epochs\n",
       "0         3.964586         3.420622           1\n",
       "1         3.964586         3.420622           2\n",
       "2         3.360586         3.302969           3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_loss</th>\n",
       "      <th>mean_valid_loss</th>\n",
       "      <th>num_epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.964586</td>\n",
       "      <td>3.420622</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.964586</td>\n",
       "      <td>3.420622</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.360586</td>\n",
       "      <td>3.302969</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_train_loss  mean_valid_loss  num_epochs\n",
       "0         3.964586         3.420622           1\n",
       "1         3.964586         3.420622           2\n",
       "2         3.360586         3.302969           3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_loss</th>\n",
       "      <th>mean_valid_loss</th>\n",
       "      <th>num_epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.964586</td>\n",
       "      <td>3.420622</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.964586</td>\n",
       "      <td>3.420622</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.360586</td>\n",
       "      <td>3.302969</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_train_loss  mean_valid_loss  num_epochs\n",
       "0         3.964586         3.420622           1\n",
       "1         3.964586         3.420622           2\n",
       "2         3.360586         3.302969           3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "orig idx 0 val: 1 | idx+1 val: 2 | diff: 1 | num_increments: 0\n",
      "no interpolation needed\n",
      "\n",
      "orig idx 1 val: 2 | idx+1 val: 3 | diff: 1 | num_increments: 0\n",
      "no interpolation needed\n",
      "\n",
      "interpolated_df with interpolated x vals:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_loss</th>\n",
       "      <th>mean_valid_loss</th>\n",
       "      <th>num_epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.964586</td>\n",
       "      <td>3.420622</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.964586</td>\n",
       "      <td>3.420622</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.360586</td>\n",
       "      <td>3.302969</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_train_loss  mean_valid_loss  num_epochs\n",
       "0         3.964586         3.420622           1\n",
       "1         3.964586         3.420622           2\n",
       "2         3.360586         3.302969           3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_loss</th>\n",
       "      <th>mean_valid_loss</th>\n",
       "      <th>num_epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.964586</td>\n",
       "      <td>3.420622</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.964586</td>\n",
       "      <td>3.420622</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.360586</td>\n",
       "      <td>3.302969</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_train_loss  mean_valid_loss  num_epochs\n",
       "0         3.964586         3.420622           1\n",
       "1         3.964586         3.420622           2\n",
       "2         3.360586         3.302969           3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Agent: il_10\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Agent'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/retro/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/retro/lib/python3.7/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/retro/lib/python3.7/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Agent'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3712093/1607740660.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'\\nAgent: {agent}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# select agent's values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0m_agent_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minterpolated_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minterpolated_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Agent'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Agent df indexed by agent:\\n{_agent_df[:15]}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/retro/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/retro/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Agent'"
     ]
    }
   ],
   "source": [
    "print(f'Original df:')\n",
    "display(df[:15])\n",
    "display(df)\n",
    "display(df[-15:])\n",
    "\n",
    "# # # OLD\n",
    "# _new_df = copy.deepcopy(df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# NEW NEW\n",
    "# for each x val, repeat y val with some minimum resolution until next x val encountered to fill out 'missing' data\n",
    "min_res = 10\n",
    "\n",
    "# convert dict vals from idx -> val dict to val list\n",
    "new_df_dict = copy.deepcopy(df).to_dict()\n",
    "for key, val in new_df_dict.items():\n",
    "    new_df_dict[key] = list(val.values())\n",
    "\n",
    "# perform x-val interpolation\n",
    "num_insertions = 0\n",
    "for idx, val in enumerate(df[xaxis][:-1]):\n",
    "    diff = df[xaxis].iloc[idx+1] - df[xaxis].iloc[idx]\n",
    "    num_increments = int(diff / min_res)\n",
    "    print(f'\\norig idx {idx} val: {val} | idx+1 val: {df[xaxis].iloc[idx+1]} | diff: {diff} | num_increments: {num_increments}')\n",
    "    if diff != min_res and num_increments != 0:\n",
    "        for i in range(num_increments):\n",
    "            print(f'i: {i} -> insert val {val+((i+1)*min_res)} at idx {idx+i+num_insertions+1}')\n",
    "            new_df_dict[xaxis].insert(idx+i+num_insertions+1, val+((i+1)*min_res))\n",
    "            for column in df.columns:\n",
    "                if column != xaxis:\n",
    "                    new_df_dict[column].insert(idx+i+num_insertions+1, df[column][idx])\n",
    "    else:\n",
    "        # no need to interpolate to next x val\n",
    "        print('no interpolation needed')\n",
    "    num_insertions += num_increments\n",
    "interpolated_df = pd.DataFrame(new_df_dict)\n",
    "print(f'\\ninterpolated_df with interpolated x vals:')\n",
    "display(interpolated_df[:15])\n",
    "display(interpolated_df)\n",
    "_new_df = copy.deepcopy(interpolated_df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# NEW\n",
    "# remove any duplicate x-values to prevent NaNs when using pd.rolling()\n",
    "new_df = defaultdict(list)\n",
    "for agent in agent_to_path.keys():\n",
    "# for agent in ['Retrospective']:\n",
    "    print(f'\\nAgent: {agent}')\n",
    "    # select agent's values\n",
    "    _agent_df = interpolated_df.loc[interpolated_df['Agent'] == agent]\n",
    "    print(f'Agent df indexed by agent:\\n{_agent_df[:15]}')\n",
    "    \n",
    "    # average entries of any duplicate x-axis values\n",
    "    agent_df = _agent_df.groupby(xaxis, as_index=False).mean()\n",
    "#     agent_df = _agent_df.drop_duplicates(subset=[xaxis], keep='first')\n",
    "    print(f'Agent df averaged over duplicate {xaxis} values:\\n{agent_df[:15]}')\n",
    "    \n",
    "    # put agent labels back into agent dataframe\n",
    "    agent_df['Agent'] = [agent for _ in range(len(agent_df))]\n",
    "    print(f'Agent df with {agent} rows re-applied:\\n{agent_df[:15]}')\n",
    "    \n",
    "#     sns.lineplot(data=agent_df, x='num_epochs', y='num_nodes')\n",
    "#     plt.show()\n",
    "    \n",
    "    for key, col in agent_df.to_dict().items():\n",
    "        print(key)\n",
    "        vals = list(col.values())\n",
    "        new_df[key].extend(vals)\n",
    "_new_df = pd.DataFrame(new_df)\n",
    "print('New df with deleted repeat values')\n",
    "display(_new_df[:15])\n",
    "display(_new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc rolling averages\n",
    "new_df = copy.deepcopy(_new_df)\n",
    "if rolling_window is not None:\n",
    "    for param in ['num_nodes', 'lp_iterations', 'R']:\n",
    "#         new_df[param] = _new_df[param].rolling(rolling_window, center=False).mean()\n",
    "#         new_df[param] = _new_df[param].rolling(rolling_window, center=False).mean().fillna(method='bfill').fillna(method='ffill')\n",
    "        new_df[param] = _new_df[param].rolling(rolling_window, center=False).mean()\n",
    "    print(f'\\nNew DF after applying rolling average:')\n",
    "    display(new_df[:15])\n",
    "    display(new_df)\n",
    "    display(new_df[-15:])\n",
    "\n",
    "# xaxis = 'num_episodes' # TEMPORARY\n",
    "    \n",
    "if xaxis == 'num_episodes':\n",
    "    xlabel = 'Episodes'\n",
    "elif xaxis == 'num_epochs':\n",
    "    xlabel = 'Learner Steps' # paper training curve\n",
    "    xlabel = 'Epochs'\n",
    "elif xaxis == 'num_actor_steps':\n",
    "    xlabel = 'Actor Steps'\n",
    "else:\n",
    "    raise Exception(f'Have not yet implemented xlabel for xaxis {xaxis}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=aesthetics.get_standard_fig_size(scaling_factor=scaling_factor, width_scaling_factor=width_scaling_factor, height_scaling_factor=height_scaling_factor))\n",
    "g = sns.lineplot(data=new_df, x=xaxis, y='num_nodes', hue='Agent', linewidth=aesthetics.linewidth, legend=legend)\n",
    "if xlim is not None:\n",
    "    plt.xlim(left=xlim[0], right=xlim[1])\n",
    "if ylim is not None:\n",
    "    plt.ylim(bottom=ylim[0], top=ylim[1])\n",
    "# plt.legend(loc='upper right')\n",
    "# ax.legend(loc='lower left', bbox_to_anchor=(0, 1.02, 1, 0.2), ncol=2, prop={'size': 3})\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, 1.3), ncol=3, prop={'size': 3})\n",
    "g.set_xlabel(xlabel)\n",
    "g.set_ylabel('Nodes')\n",
    "plt.ticklabel_format(style=xaxis_label_style, axis='x', scilimits=(0,0))\n",
    "plt.ticklabel_format(style=yaxis_label_style, axis='y', scilimits=(0,0))\n",
    "ax.tick_params(axis='both', which='major', pad=2)\n",
    "ax.xaxis.labelpad = 2\n",
    "ax.yaxis.labelpad = 2\n",
    "sns.despine(ax=ax) # remove top and right spines\n",
    "if xlog:\n",
    "    g.set(xscale='log')\n",
    "if ylog:\n",
    "    g.set(yscale='log')\n",
    "plt.gcf().patch.set_alpha(0.0)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(figsize=aesthetics.get_standard_fig_size(scaling_factor=scaling_factor, width_scaling_factor=width_scaling_factor, height_scaling_factor=height_scaling_factor))\n",
    "g = sns.lineplot(data=new_df, x=xaxis, y='lp_iterations', hue='Agent', linewidth=aesthetics.linewidth, legend=legend)\n",
    "if xlim is not None:\n",
    "    plt.xlim(left=xlim[0], right=xlim[1])\n",
    "if ylim is not None:\n",
    "    plt.ylim(bottom=ylim[0], top=ylim[1])\n",
    "g.set_xlabel(xlabel)\n",
    "g.set_ylabel('LP Iterations')\n",
    "plt.ticklabel_format(style=xaxis_label_style, axis='x', scilimits=(0,0))\n",
    "plt.ticklabel_format(style=yaxis_label_style, axis='y', scilimits=(0,0))\n",
    "ax.tick_params(axis='both', which='major', pad=2)\n",
    "ax.xaxis.labelpad = 2\n",
    "ax.yaxis.labelpad = 2\n",
    "sns.despine(ax=ax) # remove top and right spines\n",
    "if xlog:\n",
    "    g.set(xscale='log')\n",
    "if ylog:\n",
    "    g.set(yscale='log')\n",
    "plt.gcf().patch.set_alpha(0.0)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(figsize=aesthetics.get_standard_fig_size(scaling_factor=scaling_factor, width_scaling_factor=width_scaling_factor, height_scaling_factor=height_scaling_factor))\n",
    "g = sns.lineplot(data=new_df, x=xaxis, y='R', hue='Agent', linewidth=aesthetics.linewidth, legend=legend)\n",
    "plt.ticklabel_format(style=xaxis_label_style, axis='x', scilimits=(0,0))\n",
    "plt.ticklabel_format(style=yaxis_label_style, axis='y', scilimits=(0,0))\n",
    "ax.tick_params(axis='both', which='major', pad=2)\n",
    "ax.xaxis.labelpad = 2\n",
    "ax.yaxis.labelpad = 2\n",
    "sns.despine(ax=ax) # remove top and right spines\n",
    "if xlim is not None:\n",
    "    plt.xlim(left=xlim[0], right=xlim[1])\n",
    "if ylim is not None:\n",
    "    plt.ylim(bottom=ylim[0], top=ylim[1])\n",
    "g.set_xlabel(xlabel)\n",
    "g.set_ylabel('Return')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note to self\n",
    "\n",
    "Sometimes when plot e.g. num_nodes vs. learner_steps, may get a large spike with the sub-trees approach. This occurs because the actor encounters a particularly long episode (e.g. usually actor has num_nodes=50, but then encounters episode with num_nodes=10,000, num_steps=5,000). At end of epsiode, sub-trees are constructed and added to buffer, and learner will then perform num_steps/num_steps_per_update learner steps. So in this example, if num_steps_per_update=5, the learner will perform 1,000 learner steps *before gathering any more experiences*, so num nodes will be fixed at this high number for multiple learner steps/epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
